# Data Model: Evaluator Agent

**Feature**: Evaluator Agent
**Date**: 2026-02-02

## Overview

This document defines the data model for the Evaluator Agent feature. The evaluator produces a ScoreReport containing multi-dimensional quality assessments of evaluation.json files generated by the claude-evaluator framework.

---

## Core Entities

### 1. ScoreReport

The primary output document produced by the evaluator agent, containing all scores and analysis for a single evaluation.

**Identifier Pattern**: `{evaluation_id}_score_report`

**Storage Location**: `score_report.json` in the same directory as the source `evaluation.json`

**Attributes**:

| Attribute | Type | Required | Description |
|-----------|------|----------|-------------|
| evaluation_id | string | Yes | Reference to the evaluated execution's ID; must match source evaluation.json |
| aggregate_score | integer | Yes | Combined weighted score (0-100) |
| dimension_scores | DimensionScore[] | Yes | Individual scores for each quality dimension |
| rationale | string | Yes | Overall textual explanation for the scores |
| step_analysis | StepAnalysis[] | Yes | Analysis of each execution step |
| code_analysis | CodeAnalysis | No | Analysis of generated code; present only when code was produced |
| generated_at | datetime | Yes | ISO 8601 timestamp of score generation |
| evaluator_model | string | Yes | Gemini model used for evaluation |
| evaluation_duration_ms | integer | Yes | Time taken to generate the score report |

**Validation Rules**:
- `evaluation_id` must be a valid UUID v4 format
- `aggregate_score` must be in range [0, 100]
- `dimension_scores` must contain exactly 2-3 entries (task_completion required, code_quality optional, efficiency required)
- `rationale` must be non-empty (minimum 50 characters)
- `generated_at` must be a valid ISO 8601 datetime

---

### 2. DimensionScore

A score for a single quality dimension with weight and rationale.

**Attributes**:

| Attribute | Type | Required | Description |
|-----------|------|----------|-------------|
| dimension_name | DimensionType | Yes | Enum: task_completion, code_quality, efficiency |
| score | integer | Yes | Numeric score for this dimension (0-100) |
| weight | float | Yes | Weight applied in aggregate calculation (0.0-1.0) |
| rationale | string | Yes | Explanation for this dimension's score |
| sub_scores | dict[str, int] | No | Breakdown of score components (for code_quality) |

**Validation Rules**:
- `score` must be in range [0, 100]
- `weight` must be in range [0.0, 1.0]
- Sum of all dimension weights must equal 1.0
- `rationale` must be non-empty (minimum 20 characters)
- `sub_scores` keys for code_quality must be: correctness, structure, error_handling, naming

---

### 3. StepAnalysis

Analysis of an individual execution step from the evaluation.

**Attributes**:

| Attribute | Type | Required | Description |
|-----------|------|----------|-------------|
| step_index | integer | Yes | Position in execution sequence (0-indexed) |
| tool_name | string | Yes | Name of the tool invoked in this step |
| action_summary | string | Yes | Brief description of what the step accomplished |
| efficiency_flag | EfficiencyFlag | Yes | Enum: efficient, neutral, redundant |
| commentary | string | No | Additional notes or observations about this step |
| duration_ms | integer | No | Time taken for this step if available |

**Validation Rules**:
- `step_index` must be non-negative
- `tool_name` must be non-empty
- `action_summary` must be non-empty (minimum 10 characters)

---

### 4. CodeAnalysis

Analysis of code files generated or modified during the evaluation.

**Attributes**:

| Attribute | Type | Required | Description |
|-----------|------|----------|-------------|
| files_analyzed | FileAnalysis[] | Yes | List of analyzed code files |
| total_lines_added | integer | Yes | Total lines of code added across all files |
| total_lines_modified | integer | Yes | Total lines of code modified across all files |
| languages_detected | string[] | Yes | Programming languages found in analyzed files |
| quality_summary | string | Yes | Overall assessment of code quality |
| issues_found | CodeIssue[] | No | List of potential issues or anti-patterns detected |

**Validation Rules**:
- `files_analyzed` must have at least one entry if CodeAnalysis is present
- `total_lines_added` must be non-negative
- `total_lines_modified` must be non-negative

---

### 5. FileAnalysis

Analysis of a single code file.

**Attributes**:

| Attribute | Type | Required | Description |
|-----------|------|----------|-------------|
| file_path | string | Yes | Relative path to the file from workspace root |
| language | string | Yes | Detected programming language |
| lines_of_code | integer | Yes | Total lines in the file |
| analysis_status | AnalysisStatus | Yes | Enum: analyzed, skipped, file_missing |
| quality_notes | string | No | Specific observations about this file's quality |
| ast_metrics | ASTMetrics | No | Structural metrics from AST parsing (if parsing succeeded) |

**Validation Rules**:
- `file_path` must be a valid relative path
- `lines_of_code` must be non-negative
- `ast_metrics` present only when `analysis_status` is `analyzed` and language is supported

---

### 6. CodeIssue

A potential issue or anti-pattern detected in the code.

**Attributes**:

| Attribute | Type | Required | Description |
|-----------|------|----------|-------------|
| severity | IssueSeverity | Yes | Enum: high, medium, low |
| category | string | Yes | Category of issue (e.g., "error_handling", "naming", "structure") |
| file_path | string | Yes | File where the issue was found |
| line_number | integer | No | Line number where issue occurs |
| description | string | Yes | Description of the issue |
| suggestion | string | No | Suggested fix or improvement |

---

### 7. ASTMetrics

Structural metrics extracted via tree-sitter AST parsing for a single file.

**Attributes**:

| Attribute | Type | Required | Description |
|-----------|------|----------|-------------|
| function_count | integer | Yes | Number of functions/methods defined |
| class_count | integer | Yes | Number of classes defined |
| cyclomatic_complexity | float | Yes | Average cyclomatic complexity per function |
| max_cyclomatic_complexity | integer | Yes | Highest complexity of any single function |
| max_nesting_depth | integer | Yes | Maximum nesting level in code blocks |
| import_count | integer | Yes | Number of import statements |
| total_lines | integer | Yes | Total lines in file |
| code_lines | integer | Yes | Lines containing code |
| comment_lines | integer | Yes | Lines containing comments |
| blank_lines | integer | Yes | Empty lines |
| parsing_successful | boolean | Yes | Whether AST parsing succeeded |
| language | string | Yes | Detected programming language |

**Validation Rules**:
- All count fields must be non-negative
- `cyclomatic_complexity` >= 1.0 (minimum complexity)
- `code_lines + comment_lines + blank_lines` should approximately equal `total_lines`

---

## Enumerations

### DimensionType

```python
class DimensionType(str, Enum):
    task_completion = "task_completion"
    code_quality = "code_quality"
    efficiency = "efficiency"
```

### EfficiencyFlag

```python
class EfficiencyFlag(str, Enum):
    efficient = "efficient"      # Step was necessary and well-executed
    neutral = "neutral"          # Step was acceptable but could be improved
    redundant = "redundant"      # Step was unnecessary or duplicated work
```

### AnalysisStatus

```python
class AnalysisStatus(str, Enum):
    analyzed = "analyzed"        # File was successfully analyzed
    skipped = "skipped"          # File was skipped (not a source file)
    file_missing = "file_missing"  # File referenced but not found
```

### IssueSeverity

```python
class IssueSeverity(str, Enum):
    high = "high"        # Critical issue affecting functionality
    medium = "medium"    # Notable issue affecting maintainability
    low = "low"          # Minor issue or style concern
```

### TaskComplexityTier

```python
class TaskComplexityTier(str, Enum):
    simple = "simple"      # ≤10,000 tokens, ≤5 turns, ≤$0.10
    medium = "medium"      # ≤50,000 tokens, ≤15 turns, ≤$0.50
    complex = "complex"    # ≤150,000 tokens, ≤30 turns, ≤$1.50
```

---

## Relationships

```
ScoreReport (1) ────────── DimensionScore (2-3)
     │
     │ contains
     ▼
StepAnalysis (0..n)
     │
     │ references
     ▼
CodeAnalysis (0..1) ────── FileAnalysis (1..n)
                                │
                                ├── may have ──▶ CodeIssue (0..n)
                                │
                                └── contains ──▶ ASTMetrics (0..1)
```

**Relationship Details**:

| Relationship | Cardinality | Description |
|--------------|-------------|-------------|
| ScoreReport → DimensionScore | 1:2-3 | Each report has 2-3 dimension scores |
| ScoreReport → StepAnalysis | 1:n | Each report has zero or more step analyses |
| ScoreReport → CodeAnalysis | 1:0-1 | Code analysis is optional (only when code produced) |
| CodeAnalysis → FileAnalysis | 1:n | Code analysis contains one or more file analyses |
| FileAnalysis → CodeIssue | 1:n | Each file may have zero or more issues |
| FileAnalysis → ASTMetrics | 1:0-1 | Each file may have AST metrics if parsing succeeded |

---

## File Format Specifications

### score_report.json

**File Extension**: `.json`
**Location**: Same directory as source `evaluation.json`
**Filename**: `score_report.json`

**Structure**:
```json
{
  "evaluation_id": "550e8400-e29b-41d4-a716-446655440000",
  "aggregate_score": 75,
  "dimension_scores": [
    {
      "dimension_name": "task_completion",
      "score": 85,
      "weight": 0.5,
      "rationale": "Task requirements were met with minor gaps..."
    },
    {
      "dimension_name": "code_quality",
      "score": 70,
      "weight": 0.3,
      "rationale": "Code structure is good but error handling needs improvement...",
      "sub_scores": {
        "correctness": 80,
        "structure": 75,
        "error_handling": 55,
        "naming": 70
      }
    },
    {
      "dimension_name": "efficiency",
      "score": 65,
      "weight": 0.2,
      "rationale": "Token usage was slightly above baseline for task complexity..."
    }
  ],
  "rationale": "Overall, the evaluation demonstrates solid task completion...",
  "step_analysis": [
    {
      "step_index": 0,
      "tool_name": "Read",
      "action_summary": "Read the project configuration file",
      "efficiency_flag": "efficient"
    }
  ],
  "code_analysis": {
    "files_analyzed": [...],
    "total_lines_added": 150,
    "total_lines_modified": 25,
    "languages_detected": ["python"],
    "quality_summary": "Code follows project conventions with minor issues"
  },
  "generated_at": "2026-02-02T10:30:00Z",
  "evaluator_model": "gemini-2.0-flash",
  "evaluation_duration_ms": 5420
}
```

---

## Validation Rules Summary

| Entity | Rule | Error Action |
|--------|------|--------------|
| ScoreReport | aggregate_score in [0,100] | Reject report |
| ScoreReport | dimension weights sum to 1.0 | Reject report |
| ScoreReport | evaluation_id matches source | Reject report |
| DimensionScore | score in [0,100] | Reject dimension |
| DimensionScore | weight in [0.0,1.0] | Reject dimension |
| StepAnalysis | step_index >= 0 | Reject step |
| CodeAnalysis | at least one file analyzed | Skip code analysis section |
| FileAnalysis | valid file path format | Mark as file_missing |
